这一个项目是什么，这个项目你负责了什么

介绍自己，讲讲自己的项目？

你解决什么难题

项目架构图

1.各个软件的版本号？
2.spark程序用什么语言写的？
3.用Python写的什么？

大数据平台：
实时推荐系统：

1.项目流程,机器学习的项目流程,电商项目的数据流程？

2.你们一个work给分配多少资源？怎么分配的,预先分配吗?

3.怎么收集的数据？

4.你项目都负责哪一块？

5.推荐系统建模周期,这期间遇到过什么问题？

6.sample正负例样本表，标签是怎么打的？

7.数据来源是什么？

8.标签值是不是不多？（正负例样本表是标签+-1），他指的标签是维度

11.项目数据量，机器学习的项目肯定不大？

12.模型auc直多大0.92，他说挺大，我说我调的准，混淆矩阵相关算法，怎么算的？

13.还有服务器多少台?

14.介绍最近的项目？
    a.什么是协同过滤，
    b.协同过滤的值怎么求得，
    c.hive的调优，
    d.具体的pv/uv量，
    e.训练数据量，
    f.有多少个维度，
    g.特征怎么选取的，
    h.模型效果怎么评估

15.另一个项目问到了数据怎么收集的？

16.埋点怎么弄？

17.你具体负责哪一块？

18.剩下的俩项目你选个讲吧？

19.推荐系统那一套？负例少，正例多怎么办？

20.对自己每个项目做讲解，项目中的疑难点？

21.服务器如何选择？项目服务器多少台？NameNode多少台？DataNode多少台？kafka多少台？yarn多少台？

22.讲解自己的项目，遇到的问题？

23.问我数据量多大问题，和`MapReduce`运行时间问题，由于我实现没有准备好，回答不好，订单的我回答50G，微博我回答1TB，MapReduce运行时间我回答 1~2小时？

24.推荐系统矩阵列表是怎么实现的?

25.你日志处理具体怎么写的MapReduce  流程?

26.storm 项目中遇到了那些问题，怎么解决？

27.用到hbase的项目提问，实际如何处理的，java是怎么调用的，数据太多怎么优化，你所设定的数据要处理多久?

28.如何搭建实时日志分析平台，需要那些条件？

29.从设计架构，业务实现，为什么这样做，性能如何，等等问题，很多地方深入到项目中实现细节？

30.训练集和测试集的比例多大？

31.描述一下逻辑回归的特点?

32.说说项目中用到的框架？

33.项目里的业务啥的谈了谈？

34.两个项目电信和交通厅，分别用了什么架构，怎么搞得，参与搭建了吗？

35.接着又问flume几台，怎么从其他系统获取的数据，kafka几台？
我说的kafka吞吐量10万条信息每秒，我们用了一台，接着问那一台kafka挂了呢？

36.这个地方回答的不好，没搞过kafka高可用，说多台kafka也是坑，到处都是陷阱。

37.项目中那块是你做的？我说的storm实时通话分析那里，问storm怎么从kafka里读数据的
接着又问storm的spout几台，我说一个，接着说spout挂了怎么办？实在没法回答这些破问题，根本都没遇到过，吹的话那继续深入的问，一堆坑。

38.storm处理完数据写入哪里？回答hdfs和hbase   又问storm怎么写入hdfs和hbase的具体说一下。

39.问我交通厅项目主要做了哪些部分？我说spark MLlib预测路况那部分，问用的什么算法，我说逻辑线性回归

40.接着问线性回归的原理，什么场景适合线性回归，举两个例子说下。

41.模型生成完以后是怎么知道预测的好坏的？

42.对了还问了storm处理的时候利用率怎么样？怎么检测storm没有问题的，程序跑通就一定没有问题吗？反正我也不知道怎么回答了，不知道大数据有没有测试人员，怎么测试改需求?

43.自我介绍，然后就项目，电信项目我主要做了那一块？我说`storm`实时通话分析那块?

44.怎么从其他系统获取的数据，回答flume+kafka+storm这样的流程。

45.接着问flume有几台，通过什么协议获取的数据，然后就开始开火了?

46.flume收集信息的时候遇到了什么问题？怎么解决的？

47.kafka几台，我回答一台，因为kafka最大支持吞吐量10万条每秒，
接着问你们kafka传输的实际吞吐量是多少条每秒，一直追问这个，我没遇到过真不知道怎么回答，kafka传输数据的时候遇到什么错误吗？怎么解决的？又是坑，说没有遇到过。接着又问你们kafka处理的时候都没遇到过什么问题吗？弄得我无言以对，沉默。

48.日志表中的数据使用hive怎么实现，MapReduce怎么实现？题目见附件？

49.你在项目中使用的技术，解决了什么问题？

50.在你做的项目中所使用到得技术或者工具，都是做什么的？

51.flume在实际项目里面的数据采集？

52.感觉自己工作里面做的最好的是哪一块？

53：关于集群数据量，运行时间的参考(每天数据量有多大？生产集群规模有多大？)
    刚才面试面试官问了你们每天有多少数据，
    用了多少台机器，
    一般根据你写的项目，每天产生的数据量规划，假如一天数据量100g
    一般集群 规划是年数据的3倍，还有 hadoop集群3倍冗余
    假如一台服务器磁盘6T
    100G*365*3*3/6*1024g=53.4  这样的集群（一般在60台左右的服务器）
    机器的配置，
    配置 cpu 找一个稍微老一点至强cpu
    内存每台16g或32g
    每天运行多久
    一般一个作业10分钟到-几个小时不等
    一般一个作业也就几十分钟。。运行几天的很少
    有多少个MR，
    30-50个左右
    一般公司很多个作业。。
    你可以你们部门的,其他你不清楚就别说，比如数据清洗的（这里面就有很多作业了，去掉不完整数据，数据格式转换，数据字段连接，字段抽取等等），相应你简历上写的项目，，很多模板都有作业。。你细化一下
    比如推荐的作业，统计汇总的作业，用户定位的作业，
    遇到bug怎么解决，上线之后的bug怎么解决，
    一般在测试阶段就那部分线上数据测试过了。。
    如果在线上还有问题
    一般kill掉作业。。当然可以做MapReduce里面设计日志输出到单独文件，，
    根据hadoop异常日志出什么问题了。。当然hadoop每台都会有日志，当然hadoop自己的日子很庞大，，可以采用chukwa（大概看看干什么的就行，就是收集方便查看hadoop本身的日志）处理，
    然后分析作业代码。。
    有没有关心过运行时候的状态，
    MapReduce运行状态，，hadoop有监控页面
    当然也可以自己写监控程序，，MapReduce有作业监听方法，可以获取进度。。
    http://m.blog.csdn.net/blog/u014313009/38045435

51.自己熟悉大数据的部分说一下？

56。问到了最擅长那种技术？
57.问到了在实际开发的过程中遇到了什么问题？
28.你的集群多大 每天流量多少？
29.你集群中定时任务是怎么做的？
`Azkaban`

62.是否参加过CodeReview？有什么心得？
阐述一下最近开发的项目，以及担任的角色位置
项目中数据倾斜的场景和解决方案
kafka有做过哪些调优

数据仓库的理解?
1、数仓:olap，非实时数据(联机分析 多维度);
    普通rdbms:实时交互
2、数仓里面有原始表和维度表，维度表可以使用拉链表的方式来实现